{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AksharaVenkatesh\\AppData\\Local\\Temp\\ipykernel_8876\\4019890883.py:46: RuntimeWarning: invalid value encountered in divide\n",
      "  features = (features - features.mean(axis=0)) / features.std(axis=0)\n",
      "C:\\Users\\AksharaVenkatesh\\AppData\\Local\\Temp\\ipykernel_8876\\4019890883.py:32: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  policy['Effective_Date'] = pd.to_datetime(policy['Effective_Date'])\n",
      "C:\\Users\\AksharaVenkatesh\\AppData\\Local\\Temp\\ipykernel_8876\\4019890883.py:33: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  policy['Expiration_Date'] = pd.to_datetime(policy['Expiration_Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AksharaVenkatesh\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3445.4199"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AksharaVenkatesh\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 3432.2346 - val_loss: 96.9242\n",
      "Epoch 2/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 162.9027 - val_loss: 95.5894\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 154.9041 - val_loss: 96.0665\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 159.7021 - val_loss: 95.7748\n",
      "Epoch 5/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 153.7381 - val_loss: 95.8563\n",
      "Epoch 6/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 157.2836 - val_loss: 95.8217\n",
      "Epoch 7/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 157.2221 - val_loss: 96.4444\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 101.2740\n",
      "MSE: 99.21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Conv1D, MaxPooling1D, Dropout, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load and preprocess data (assuming this part is done as previously described)\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\AksharaVenkatesh\\\\OneDrive - ConceptVines\\\\High Peak\\\\insurance_data.csv\")\n",
    "# Preprocess the data\n",
    "policyholder_ids = df['Policyholder_ID'].unique()\n",
    "n_policyholders = len(policyholder_ids)\n",
    "\n",
    "# Create a dictionary to map policyholder IDs to integers\n",
    "policyholder_id_map = {policyholder_id: i for i, policyholder_id in enumerate(policyholder_ids)}\n",
    "\n",
    "# Create a list to store the preprocessed data\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Iterate over the policyholders\n",
    "for policyholder_id in policyholder_ids:\n",
    "    # Get the policyholder's data\n",
    "    policyholder_data = df[df['Policyholder_ID'] == policyholder_id]\n",
    "    \n",
    "    # Create a list to store the policyholder's features\n",
    "    features = []\n",
    "    \n",
    "    # Iterate over the policyholder's policies\n",
    "    for i, policy in policyholder_data.iterrows():\n",
    "        # Convert dates to timestamps and extract policy features\n",
    "        policy['Effective_Date'] = pd.to_datetime(policy['Effective_Date'])\n",
    "        policy['Expiration_Date'] = pd.to_datetime(policy['Expiration_Date'])\n",
    "        policy_features = [\n",
    "            policy['Premium'],\n",
    "            policy['Coverage_Amount'],\n",
    "            policy['Effective_Date'].timestamp(),\n",
    "            policy['Expiration_Date'].timestamp()\n",
    "        ]\n",
    "        \n",
    "        # Append the policy features to the list\n",
    "        features.append(policy_features)\n",
    "    \n",
    "    # Convert the list of features to a numpy array and normalize\n",
    "    features = np.array(features)\n",
    "    features = (features - features.mean(axis=0)) / features.std(axis=0)\n",
    "    \n",
    "    # Append the preprocessed data to the lists\n",
    "    X.append(features)\n",
    "    y.append(policyholder_data['Longevity'].iloc[0])\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# Define the model architecture\n",
    "input_shape = (X.shape[1], X.shape[2])\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Temporal Convolutional Layer with 'same' padding to handle short sequences\n",
    "conv_layer = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "conv_layer = MaxPooling1D(pool_size=2, padding='same')(conv_layer)\n",
    "\n",
    "# Long-Short Term Memory Layer with return_sequences=True\n",
    "lstm_layer1 = LSTM(units=128, return_sequences=True)(conv_layer)\n",
    "lstm_layer2 = LSTM(units=64, return_sequences=True)(lstm_layer1)  # Ensuring LSTM outputs sequences\n",
    "\n",
    "# Attention Mechanism\n",
    "attention_layer = Attention()([lstm_layer2, lstm_layer2])  # Attention applied here\n",
    "\n",
    "# Dense Layer\n",
    "dense_layer = Dense(units=64, activation='relu')(attention_layer)\n",
    "dense_layer = Dropout(rate=0.2)(dense_layer)\n",
    "\n",
    "# Output Layer\n",
    "output_layer = Dense(units=1)(dense_layer)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.001)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X, y)\n",
    "print(f'MSE: {mse:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
